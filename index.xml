<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>digikar's microblog</title><link>https://digikar99.github.io/microblog/</link><description>Recent content on digikar's microblog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 16 Feb 2026 21:46:40 +0100</lastBuildDate><atom:link href="https://digikar99.github.io/microblog/index.xml" rel="self" type="application/rss+xml"/><item><title>4 months in MacOS - A Visceral Dislike of Computing</title><link>https://digikar99.github.io/microblog/p/macos-dislike/</link><pubDate>Mon, 16 Feb 2026 21:46:40 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/macos-dislike/</guid><description>&lt;p&gt;&lt;em&gt;This is a rant. So, in case you are looking for something useful, you can close the page.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;These years in Apple Hardware have been interesting. The M-series chips are remarkable - &lt;del&gt;good&lt;/del&gt; amazing battery life, performance, and cooling. Put on Power-Saving mode, and you can breeze through a work day despite zoom calls, and even two work days if you do not stream video (calls).&lt;/p&gt;
&lt;p&gt;I have been using MacOS for over four months now. It works with a single track workflow. But for some reason, I developed a visceral dislike for computing. I no longer wanted to touch my macbook once I was back home after the work day (= university).&lt;/p&gt;
&lt;p&gt;I also own another laptop - Thinkpad with KDE Plasma. The past month, I began frequenting it more. And suddenly, I was regaining the joy I had lost. I &lt;em&gt;looked forward to using my laptop even after the work day&lt;/em&gt;. I could sleep myself to it if I no obligations the next day or was reminded that its battery was about to end.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s true I&amp;rsquo;ve been using KDE for a few years. Before that, I was an XFCE4 fan for half a decade. It is also true the KDE is on a Thinkpad. But I have used Windows for a decade before that. So, mere familiarity cannot explain this &lt;em&gt;visceral dislike for computing&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;On both KDE (and XFCE4 before that), my workflow has spanned 5, 6, 7 or even 8 desktops, spanning different areas of life - 2-3 desktops for different courses, projects or university activities, another 1-2 for my random programming activities, another 2 for lisp-related projects, and another one for &amp;ldquo;miscellaneous&amp;rdquo;. I have them all in the corner of my screen. When the context switches, I glance at the corner of my screen and switch. The desktops and application switchers are pretty customizable, and allow you to isolate windowed applications on one desktop from another. But the icing on the cake, multiple instances of the applications behave very nicely. Opening any application again creates a new instance (usually), no matter if there was an instance on another desktop. This aids further isolation of context.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://digikar99.github.io/microblog/p/macos-dislike/kde.png"
width="1920"
height="1080"
srcset="https://digikar99.github.io/microblog/p/macos-dislike/kde_hu_4ea0444206c93e5f.png 480w, https://digikar99.github.io/microblog/p/macos-dislike/kde_hu_28cb2230e061d3e6.png 1024w"
loading="lazy"
alt="My KDE Plasma Desktop at the moment I was writing this"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
&gt;&lt;/p&gt;
&lt;p&gt;Contrast this with MacOS. One needs more than a glance to even check what space (=desktop) I am in and what other spaces I can switch to. It&amp;rsquo;s a multi-finger swipe, and then one more to return back to the application I was working in. MacOS (and other dumbed-down operating systems including Android and iOS) hate multiple instances of apps. Opening an application again from another desktop will greet you with an invisible window, from which you can figure out if you are in the same app as before because the app did not open for some reason or the invisible window or, perhaps, the app is slightly heavy and still in the process of being opened. There are certainly ways to open&lt;/p&gt;
&lt;p&gt;&lt;img src="https://digikar99.github.io/microblog/p/macos-dislike/macos.png"
width="1175"
height="765"
srcset="https://digikar99.github.io/microblog/p/macos-dislike/macos_hu_fe1891751e154629.png 480w, https://digikar99.github.io/microblog/p/macos-dislike/macos_hu_57a38825944b78a7.png 1024w"
loading="lazy"
alt="My MacOS Desktop at the moment I was writing this"
class="gallery-image"
data-flex-grow="153"
data-flex-basis="368px"
&gt;&lt;/p&gt;
&lt;p&gt;Will I &lt;em&gt;ever&lt;/em&gt; get over this visceral dislike for MacOS? Perhaps, when KDE comes to it. But if the single vs multi-instance apps is a source for my dislike, then nothing short of a MacOS restructuring perhaps.&lt;/p&gt;
&lt;p&gt;Will more affordable Thinkpads &lt;em&gt;ever&lt;/em&gt; get longer battery lives? I am more betting my hopes on this. Hopefully, in a few years, long-battery life T-series Thinkpads (or X-series, a human can dream :&amp;rsquo;)) will become affordable that I will just grab an awesome deal some day :).&lt;/p&gt;
&lt;p&gt;I myself am not sure what drives my dislike. But, at this point, I don&amp;rsquo;t think the reason is &amp;ldquo;you just have to get used to it&amp;rdquo;.&lt;/p&gt;</description></item><item><title>Why Climate Action needs to focus on Corporate Production and not just Individual Consumption?</title><link>https://digikar99.github.io/microblog/p/climate-action/</link><pubDate>Sat, 31 Jan 2026 18:01:24 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/climate-action/</guid><description>&lt;p&gt;&lt;em&gt;What can I do to reduce climate change?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If you are a resident of the 21st century, still under 60, rich enough that you do not need to worry about the cost of your next meal, and have any sense of obligation towards the society at large, that question might have crossed your mind. Perhaps, it even keeps you awake at night. Climate anxiety is a thing. (I wrote about it before &amp;ndash; &lt;a class="link" href="../climate-anxiety-dec-2025/" &gt;here&amp;rsquo;s something that may help&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Perhaps, you have even been successful in converting your worries into concrete actions. You consume less meat, avoid flights, buy products that say that are environment-friendly, or even better, avoid buying anything unnecessary at all. Perhaps you converted your house into solar. You try to cut down your carbon footprint as much as possible. And even motivate others to do the same. You hope that some day, majority of humanity will follow suit and opt for an environment friendly lifestyle. And, perhaps then, the climate crisis will be averted, right? Right?&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;p&gt;Right?&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;p&gt;R.I.G.H.T.?!&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In 2005, fossil fuel company &lt;a class="link" href="https://en.wikipedia.org/wiki/BP" target="_blank" rel="noopener"
&gt;BP&lt;/a&gt; hired the large advertising campaign &lt;a class="link" href="https://en.wikipedia.org/wiki/Ogilvy_%28agency%29" target="_blank" rel="noopener"
&gt;Ogilvy&lt;/a&gt; to popularize the idea of a carbon footprint for individuals. The campaign instructed people to calculate their personal footprints and provided ways for people to &amp;ldquo;go on a &lt;a class="link" href="https://en.wikipedia.org/wiki/Climatarian_diet" target="_blank" rel="noopener"
&gt;low-carbon diet&lt;/a&gt;&amp;rdquo;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;- source: &lt;a class="link" href="https://en.wikipedia.org/wiki/Carbon_footprint#History" target="_blank" rel="noopener"
&gt;https://en.wikipedia.org/wiki/Carbon_footprint#History&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A person from the richest 0.1% produces more carbon pollution in a day than someone in the bottom 50% produces all year.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;- source: &lt;a class="link" href="https://www.oxfam.org/en/press-releases/person-richest-01-produces-more-carbon-pollution-day-someone-bottom-50-produces-all" target="_blank" rel="noopener"
&gt;https://www.oxfam.org/en/press-releases/person-richest-01-produces-more-carbon-pollution-day-someone-bottom-50-produces-all&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Why would a fossil fuel company popularize carbon footprint?&lt;/li&gt;
&lt;li&gt;Let&amp;rsquo;s assume majority of humans follow suit towards a environment-friendly lifestyle, may be 50%, or even 90%. But if &lt;a class="link" href="https://policy-practice.oxfam.org/resources/carbon-inequality-kills-why-curbing-the-excessive-emissions-of-an-elite-few-can-621656/" target="_blank" rel="noopener"
&gt;carbon inequality&lt;/a&gt; remains, does that mean, just the tiny non-environmentally-compliant 1% (or even 0.1%) humans produce enough emissions to not only cause but also accelerate the climate crisis?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The answer to the second question is a short &amp;ldquo;unfortunately, yes&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;About the first. Why would a fossil fuel company popularize carbon footprint?&lt;/p&gt;
&lt;p&gt;Perhaps the company is ethical? The most ethical thing a fossil fuel company can do to mitigate the climate crisis is to stop being a fossil fuel company. Just change the business. Is money more important than life? A short read at BP&amp;rsquo;s wikipedia page, including sections of &amp;lsquo;Polical Influence&amp;rsquo;, reveals that &lt;a class="link" href="https://en.wikipedia.org/wiki/BP#Political_influence" target="_blank" rel="noopener"
&gt;for BP, money indeed is more important than life&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;BP is not alone. &lt;a class="link" href="https://www.theguardian.com/environment/2026/jan/21/carbon-dioxide-co2-emissions-fossil-fuel-firms-study" target="_blank" rel="noopener"
&gt;Half of world’s CO2 emissions come from just 32 fossil fuel firms.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;But.&lt;/p&gt;
&lt;p&gt;But, these companies exist because we all consume their goods and services, right? If we just stop consuming their goods and opt for better companies, individual actions can avert the climate crisis, right? Look at the bottom 50% of humans. &lt;a class="link" href="https://wir2022.wid.world/chapter-1/" target="_blank" rel="noopener"
&gt;The average income of the bottom 50% of humans was about $3920 per year.&lt;/a&gt; That&amp;rsquo;s about INR 4,26,000 or 32,300 Yuan annually. If you factor in regional disparities, the picture should be sharper. The poorest 50% simply do not consume enough to have any significant impact on the climate. Honestly, having grown up in India, if I did not need to factor in retirement funds, the ever-rising housing prices, and (future) children&amp;rsquo;s college fees, INR 4,00,000 is actually a sufficient income for a comfortable life in an Indian town. So, what exactly do the rich consume that throws their carbon pollution off the charts compared to the rest of us?&lt;/p&gt;
&lt;p&gt;Before that, just remember that &lt;a class="link" href="https://mashable.com/feature/carbon-footprint-pr-campaign-sham" target="_blank" rel="noopener"
&gt;carbon footprint as popularized in the media was a tool used by fossil fuel companies to divert attention from their own misdeeds&lt;/a&gt;. That&amp;rsquo;s not to say, individual actions do not matter. But solely focusing on them would completely miss the climate goals, given the carbon (and income) inequality highlighted above.&lt;/p&gt;
&lt;p&gt;The best illustration of how the rich consume is perhaps made not by text, but by videos:&lt;/p&gt;
&lt;div class="video-wrapper"&gt;
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/69DFis2WgMQ"
allowfullscreen
title="YouTube Video"
&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;At 20 minutes, it is several times longer than the average instagram or youtube shorts, but hopefully, it is a nice watch down the subway, or during your dinner or lunch break!&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;p&gt;The standard guess is that the rich use private jets and yachts that pollute. And that is certainly true. The rich certainly consume more. 1000s of times more than the poorest. But when we say that &lt;a class="link" href="https://www.theguardian.com/environment/2023/nov/20/twelve-billionaires-climate-emissions-jeff-bezos-bill-gates-elon-musk-carbon-divide" target="_blank" rel="noopener"
&gt;12 billionaires pollute more than 2.1 million homes&lt;/a&gt;, we are looking at a million-fold disparity. The difference in consumption habits only accounts for a thousand-fold inequality.&lt;/p&gt;
&lt;p&gt;In terms of consumption alone, Taylor Swift emits more than the CEO of Exxonmobil! However, persons like the latter are also in charge of &lt;em&gt;highly polluting means of production&lt;/em&gt;, such as fossil fuel and cement. &lt;a class="link" href="https://en.wikipedia.org/wiki/Holcim" target="_blank" rel="noopener"
&gt;Holcim&lt;/a&gt;&amp;rsquo;s cement production in 2020 alone produced about 19,000 times the carbon emissions of Taylor Swift&amp;rsquo;s private jets! In general, the cement industry is owned by roughly 7,000 individuals (&amp;lt; 1/1,000,000 of humans) and emits about 8% (about 1/12) of the global carbon emissions. The worse case holds for the fossil-fuel industry with &lt;a class="link" href="https://www.theguardian.com/sustainable-business/2017/jul/10/100-fossil-fuel-companies-investors-responsible-71-global-emissions-cdp-study-climate-change" target="_blank" rel="noopener"
&gt;100 companies (their owners and the board) accountable for 70% of global emissions&lt;/a&gt;. It is also not the case that there are no solutions. There exist alternative means of production that can still drive profits. But perhaps, this is lesser profit than what can change the rich owner&amp;rsquo;s minds.&lt;/p&gt;
&lt;p&gt;Besides controlling the means of production, the rich owners also engage in political lobbying influencing legal policies and public opinions. Remember the carbon footprint debacle?&lt;/p&gt;
&lt;p&gt;Essentially, if you are rich, I commend you for reading this far. If you invest, you can choose to invest in environment friendly firms.&lt;/p&gt;
&lt;p&gt;For the others, perhaps our actions need to be more thoughtful in terms of the impact they produce. They need to consider not only our individual consumption, but the means of production themselves, that are the final source of all the crisis. What concrete actions should we take? That&amp;rsquo;s a good question I don&amp;rsquo;t have the answer to.&lt;/p&gt;</description></item><item><title>The role of Open Source and Data Privacy for Security</title><link>https://digikar99.github.io/microblog/p/data-security/</link><pubDate>Tue, 13 Jan 2026 18:08:32 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/data-security/</guid><description>&lt;p&gt;Internet has been amazing. You send a message. And it reaches the other end of the Earth in seconds. Even more, you can communicate with live video and audio! It seems magical.&lt;/p&gt;
&lt;p&gt;Yet it is not. All communication is transmission of energy. Energy travels through space &amp;ndash; which may be occupied by matter or may not. Most space through which communications travel is openly available to everyone. The same space is used by multiple communicators. Does that mean everyone can access the messages I send over the internet?&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s a scary thought. All your bank account details, passwords, private messages, your voice, your tone, your looks*, all travel over the internet. Are these all available to the public at large? (*You know now with generative AI, your voice and looks are sufficient to prepare videos as if you had done or said things you hadn&amp;rsquo;t!)&lt;/p&gt;
&lt;p&gt;Unfortunately, in an unencrypted world, it would be true that everyone can see everyone&amp;rsquo;s messages. You can read malicious users&amp;rsquo; messages, and they can read yours. Furthermore, what even determines that a message your messaging app says was sent by your friend was really sent by your friend? And not someone else disguised as your friend?&lt;/p&gt;
&lt;p&gt;Humans, some of them, are smart. These problems have been known since the dawn of the internet in the 20th century, possibly before. Solutions have been devised against them. Today, for most communication problems in the general, we know that&lt;/p&gt;
&lt;center&gt;
If communications satisfy certain assumptions, then certain particular security benefits are &lt;em&gt;guaranteed&lt;/em&gt;.
&lt;/center&gt;
&lt;p&gt;In other words,&lt;/p&gt;
&lt;center&gt;
If we build communication softwares that satisfy certain assumptions, then we get certain particular security benefits.
&lt;/center&gt;
&lt;p&gt;These benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Knowing that the message your messaging app says was sent by a friend was really sent by your friend&amp;rsquo;s device.&lt;/li&gt;
&lt;li&gt;Ensuring that only you and your friend can read messages sent to each other. That is, your messages are inaccessible to anyone else.&lt;/li&gt;
&lt;li&gt;&amp;hellip; and many more &amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In general, the &amp;ldquo;friend&amp;rdquo; may be any other communication end-point, such as your bank, where security is just as important if not more. However,&lt;/p&gt;
&lt;center&gt;
How do we know that communication softwares actually satisfy the assumptions required for security?
&lt;/center&gt;
&lt;p&gt;Three methods:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We trust the word of the person or institute who developed the software &lt;em&gt;and make profits from the software&lt;/em&gt;. In general, the greater motive here is making monetary profits, since that is a very essential aspect of livelihood of the person or institute.&lt;/li&gt;
&lt;li&gt;We trust the word of the person or institute who is &lt;em&gt;motivated to study and develop the software and ensure the software satisfies the assumptions required for security&lt;/em&gt;. In general, monetary profit as a motive is either absent or very much secondary.&lt;/li&gt;
&lt;li&gt;We study the workings of the software ourselves.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both 2nd and 3rd methods require that how the software works is publicly accessible. This means the source code (but also the infrastructure details) are publicly available. In other words,&lt;/p&gt;
&lt;center&gt;
Trusting the claim that a particular software is secure becomes easier when the workings of the software are publicly known, that is, it is open source.
&lt;/center&gt;
&lt;p&gt;How to find open source softwares?&lt;/p&gt;
&lt;center&gt;
An easy method to find the open source alternative for a software is to simply google "open source alternative to &lt;em&gt;software that interests you&lt;/em&gt;". You can also append the search by "site:reddit.com" or "site:stackexchange.com" or you can also consult one of your tech-geek friends or family-members.
&lt;/center&gt;
&lt;p&gt;It is trivial to see that between two people or institutes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One who is motivated by monetary profits&lt;/li&gt;
&lt;li&gt;Another who is motivated by software security&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second category of people or institutes would end up with more secure softwares in any particular class of softwares in the longer run. In other words, in the longer run, the first category of people or institutes are likely to make mistakes even if, besides making money, they too want to make their softwares secure. This is simply because, for the software developers, motivation for software security drives learning and brings in the time to spend on the software and make changes that may go against the monetary motivation.&lt;/p&gt;
&lt;p&gt;That people and software developers can make mistakes brings us to the second point of this blog post. Your data includes - your name, phone numbers, email addresses, passwords, bank account numbers, people or institutes you send messages to or receive messages from, what messages you send, which websites you access, how frequently, at what time, for how long, your phone location, when do you leave your home, office or visit a friend, and much more.&lt;/p&gt;
&lt;center&gt;
You would &lt;em&gt;WISH&lt;/em&gt; that the banks, institutes, and messaging softwares that have access to your data are actually storing them securely, in a manner that does not permit thieves and malicious actors from misusing your data.
&lt;/center&gt;
&lt;p&gt;This is also called a data breach. In 2025 alone, there were &lt;a class="link" href="https://www.cybersecurity-insiders.com/top-5-banking-data-breaches-of-2025-2/" target="_blank" rel="noopener"
&gt;at least 5 data breaches with banking softwares&lt;/a&gt; resulting in millions of individuals losing their banking details to malicious hackers. It is not just banking softwares. Data breaches can happen with &lt;a class="link" href="https://therecord.media/8-million-affected-zoomcar-data-breach" target="_blank" rel="noopener"
&gt;car companies&lt;/a&gt;, &lt;a class="link" href="https://en.wikipedia.org/wiki/Kido_International_cyberattack" target="_blank" rel="noopener"
&gt;education providers&lt;/a&gt;, &lt;a class="link" href="https://www.computing.co.uk/news/2025/security/asahi-breach-exposes-customers-details" target="_blank" rel="noopener"
&gt;beer companies&lt;/a&gt;, &lt;a class="link" href="https://www.scworld.com/brief/almost-27m-sk-telecom-sim-records-compromised" target="_blank" rel="noopener"
&gt;sim providers&lt;/a&gt;, &lt;a class="link" href="https://www.yahoo.com/news/articles/kering-confirms-data-breach-192611717.html" target="_blank" rel="noopener"
&gt;luxury brands&lt;/a&gt;, and pretty much everything that is connected to internet.&lt;/p&gt;
&lt;p&gt;If the softwares were open source, it would be easier to ensure security. However, the next best thing to open source might be data privacy. How do you prevent your data from being misused?&lt;/p&gt;
&lt;center&gt;
To prevent your data from being misused, you restrict your data from being accessible. That is, you keep your data &lt;em&gt;private&lt;/em&gt;.
&lt;/center&gt;
&lt;p&gt;How do you make your data more private? This is a bit like asking &lt;em&gt;How do I make myself more healthy?&lt;/em&gt; There&amp;rsquo;s no simple answer, although one can try some guidelines! See &lt;a class="link" href="https://www.reddit.com/r/privacy/wiki/index/#wiki_what_can_i_do_to_protect_my_privacy.3F" target="_blank" rel="noopener"
&gt;here&lt;/a&gt; or &lt;a class="link" href="https://www.reddit.com/r/privacy/comments/1cposnq/starting_from_scratch_how_to_delete_my_online/" target="_blank" rel="noopener"
&gt;here&lt;/a&gt; for a detailed guide. Here&amp;rsquo;s an attempt at some guidelines:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Reduce reliance on closed source softwares for information processing. This includes Microsoft Word, Powerpoint, Excel, as well as Google Docs, Slides, and Sheets, and also Apple. Of course, you may be forced to use these apps &lt;em&gt;because your colleague uses them&lt;/em&gt;. In that case, either convince them to shift to open source alternatives or use the open source alternatives for your personal use cases. Simple alternatives include &lt;a class="link" href="https://www.markdownguide.org/getting-started/" target="_blank" rel="noopener"
&gt;markdown&lt;/a&gt;, &lt;a class="link" href="https://www.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes" target="_blank" rel="noopener"
&gt;latex&lt;/a&gt;, and &lt;a class="link" href="https://blog.documentfoundation.org/blog/2025/05/16/what-is-odf/" target="_blank" rel="noopener"
&gt;open document formats&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Try out &lt;a class="link" href="https://www.youtube.com/watch?v=2W7Pi26ZHm8" target="_blank" rel="noopener"
&gt;Kubuntu&lt;/a&gt; on newer laptops or &lt;a class="link" href="https://www.youtube.com/watch?v=lnzMl7BFM0Q" target="_blank" rel="noopener"
&gt;Xubuntu&lt;/a&gt; to renew old laptops. Be sure to use the &amp;ldquo;Long-Term Support (LTS)&amp;rdquo; versions, currently 24.04. You can also try it as a &lt;a class="link" href="https://www.youtube.com/watch?v=2uxX0UtInhQ" target="_blank" rel="noopener"
&gt;virtual machine&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Switch to secure open-source messaging softwares:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class="link" href="https://signal.org/" target="_blank" rel="noopener"
&gt;Signal&lt;/a&gt; or &lt;a class="link" href="https://molly.im/" target="_blank" rel="noopener"
&gt;Molly&lt;/a&gt; &lt;em&gt;in addition to&lt;/em&gt; Whatsapp, Messenger, Instagram.&lt;/li&gt;
&lt;li&gt;&lt;a class="link" href="https://jitsi.guide/blog/jitsi-vs-zoom/" target="_blank" rel="noopener"
&gt;Jitsi&lt;/a&gt; &lt;em&gt;in addition to&lt;/em&gt; Zoom or Google Meet or Teams&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;a class="link" href="https://www.pcmag.com/explainers/why-you-need-a-password-manager-and-how-to-choose-the-right-one" target="_blank" rel="noopener"
&gt;password managers&lt;/a&gt; like &lt;a class="link" href="https://bitwarden.com/" target="_blank" rel="noopener"
&gt;Bitwarden&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;hellip; You are motivated enough. Read one of those detailed guides now :)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="to-sum-up"&gt;To sum up
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Open source aids security. You can find open source alternatives by simply googling &amp;ldquo;open source alternatives to &amp;lt;app you want&amp;gt;&amp;rdquo;. Optionally, you can append the search with &amp;ldquo;site:reddit.com&amp;rdquo; or &amp;ldquo;site:stackexchange.com&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Privacy aids security. Privacy is a bit like moving towards a healthy lifestyle. There are lots of small changes in the way. See &lt;a class="link" href="https://www.reddit.com/r/privacy/wiki/index/#wiki_what_can_i_do_to_protect_my_privacy.3F" target="_blank" rel="noopener"
&gt;this&lt;/a&gt; or &lt;a class="link" href="https://www.reddit.com/r/privacy/comments/1cposnq/starting_from_scratch_how_to_delete_my_online/" target="_blank" rel="noopener"
&gt;this&lt;/a&gt; for a detailed guide.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>The Inevitability of Environmental Collapse with Rapid Resource Extraction</title><link>https://digikar99.github.io/microblog/p/rapidity-collapse/</link><pubDate>Thu, 01 Jan 2026 11:14:23 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/rapidity-collapse/</guid><description>&lt;p&gt;Imagine being stranded on a small island. The island only has a few coconut trees, no fish or other vegetation or other food sources; coconuts are the only source of food. Furthermore, in about two weeks, it will be the full moon. The island is a &lt;a class="link" href="https://en.wikipedia.org/wiki/Vanishing_island" target="_blank" rel="noopener"
&gt;vanishing one&lt;/a&gt; - the island submerges during the full and new moon. In other words, you have two choices:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Keep eating the coconuts from coconut trees, and sink and die as the island submerges during the upcoming full moon.&lt;/li&gt;
&lt;li&gt;Cut the coconut trees and make them into a raft. This will cut down your food source. But hopefully, if you know or learn how to make a good raft, you might survive!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The scenario might seem artificial, but turns out to be very real. What do I mean?&lt;/p&gt;
&lt;p&gt;Consider that life as we know it is stranded on the planet Earth.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If we do just the bare minimum to keep ourselves surviving, some day, some cosmic event will eventually wipe us out. &lt;a class="link" href="https://en.wikipedia.org/wiki/Cretaceous%E2%80%93Paleogene_extinction_event" target="_blank" rel="noopener"
&gt;It happened with dinosaurs&lt;/a&gt;, remember?&lt;/li&gt;
&lt;li&gt;Alternatively, we could extract resources from our environment. Lacking &lt;a class="link" href="https://en.wikipedia.org/wiki/Omniscience" target="_blank" rel="noopener"
&gt;omniscience&lt;/a&gt;, we do not know what the effect of our resource extraction will be. Perhaps, it might trigger events that themselves either harm us or even lead to the very extinction we are trying to avoid!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It is not even a case of underdeveloped science. Science provides the &lt;em&gt;how to&lt;/em&gt; of reasoning over nature. The &lt;em&gt;over what&lt;/em&gt; are the specific scenarios that occur in the particular natural habitat. It doesn&amp;rsquo;t take rocket science to realize that the release of trapped $CO_2$, methane, or microbes can pose a threat as a mine is excavated. However, no amount of science can tell us that &lt;em&gt;there is&lt;/em&gt; trapped $CO_2$, methane or microbes in the mine. That requires &lt;em&gt;exploring&lt;/em&gt; or inspecting the environment. Furthermore, &lt;em&gt;can&lt;/em&gt; pose a threat does not mean &lt;em&gt;will&lt;/em&gt; pose a threat. And again, lacking omniscience, it is not possible to make perfect predictions.&lt;/p&gt;
&lt;p&gt;Rapid resource extraction &amp;ndash; which does not bother or even denies inspecting the side-effects of the particular resource extraction &amp;ndash; will thus &lt;em&gt;eventually&lt;/em&gt; lead to environmental collapse. It would merely be luck that a civilization survives any particular length of rapid resource extraction.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;How rapid?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Rapid enough that the resulting environmental collapse triggers events on a scale the civilization cannot deal with. Climate change is one example.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The alternative?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Slow down.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;How slow?&lt;/em&gt;&lt;/p&gt;
&lt;center&gt;
If the civilization can restructure or metamorphize itself into &lt;em&gt;not&lt;/em&gt; requiring any more resources, or at least, &lt;em&gt;only minimally more&lt;/em&gt; resources, that would be ideal.
&lt;/center&gt;
&lt;p&gt;In other words, if the civilization can make do with the resources it already has at hand, it should avoid extracting more resources. At the same time, it should develop its scientific understanding as well as explore its environment to better understand the effects of particular resource extractions. As the knowledge of these effects becomes available, only then, should it extract the resources. However, it will be competing against the cosmic events. But hopefully, &amp;ldquo;industrialization and modernization&amp;rdquo; over a span of 40,000 years rather than 400 years can easily be a sweet spot that does both&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Develop tools to overcome the cosmic event.&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t harm oneself or go extinct by environmental collapse triggered by rapid resource extraction.&lt;/li&gt;
&lt;/ol&gt;
&lt;center&gt;Slow down.&lt;/center&gt;
&lt;p&gt;&lt;a class="link" href="https://discuss.leeds.ac.uk/2020/02/26/food-inequality-humanitys-biggest-moral-failure/" target="_blank" rel="noopener"
&gt;Extremely unequal distribution of resources not insufficiency&lt;/a&gt; is the &lt;a class="link" href="https://blogs.egu.eu/geolog/2025/07/11/the-false-narrative-of-over-population-why-malthus-had-it-wrong-when-it-comes-to-global-resources/" target="_blank" rel="noopener"
&gt;root of modern global problems&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the richest 1% of humanity now produce as much carbon as the poorest two-thirds combined. Likewise, the top 10% of emitters account for half of all global $CO_2$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The civilization must optimize the use of its resources to meet the needs of its individuals and develop science and environmental knowledge while &lt;em&gt;trying&lt;/em&gt; not to extract further resources. Any growth, development, or betterment that stems from resource extraction instead of optimization is a short-sighted move that &lt;span style="color:red; text-decoration:line-through"&gt;can&lt;/span&gt; &lt;span style="color:green"&gt;will&lt;/span&gt; pose an extinction threat to the civilization.&lt;/p&gt;
&lt;p&gt;Note that resource optimization has to be carried out at the scale of civilization, particularly amongst its top resource extractors. Resource optimization amongst the bottom resource extractors without the top is futile. In case this is not obvious, suppose:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group A comprising 1 billion people consume 90 units of a resource&lt;/li&gt;
&lt;li&gt;Group B comprising 9 billion people consume 10 units of a resource&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Combined, the two groups consume 100 units of the resource.&lt;/p&gt;
&lt;p&gt;What will happen if group B starts consuming 50% less resources? Naively, 90% people consuming 50% less resources sounds like a great win! However -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group A will still consume 90 units&lt;/li&gt;
&lt;li&gt;Group B will consume 5 units&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Combined, the two groups still consume 95 units of the resource. The resource saving is a mere 5%, extraordinarily different from the intuition generated by &amp;ldquo;90% people consuming 50% less resources&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;What will happen if &lt;em&gt;group A&lt;/em&gt; starts consuming 50% less resources?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group A will consume 45 units&lt;/li&gt;
&lt;li&gt;Group B will continue to consume 10 units&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Combined, the two groups consume 55 units of the resource! A conservation of 45% resources is resulted from merely 10% of the top resource extractors cutting their extractions in half.&lt;/p&gt;
&lt;p&gt;Inequality itself is not a problem; extreme inequality of the above kind is. It is not a mere &amp;ldquo;problem of ethics&amp;rdquo; we can disagree over but a &amp;ldquo;survival problem&amp;rdquo; that will kill everyone. It &lt;span style="color:green"&gt;will&lt;/span&gt; lead to extinction.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a short lunch-time video to convey the concrete effects of what abstract &amp;ldquo;2C&amp;rdquo; rise in average temperature means.&lt;/p&gt;
&lt;div class="video-wrapper"&gt;
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/2njn71TqkjA"
allowfullscreen
title="YouTube Video"
&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;Here&amp;rsquo;s another&lt;/p&gt;
&lt;div class="video-wrapper"&gt;
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/MBKZWKeKYqE"
allowfullscreen
title="YouTube Video"
&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;Care to be the saviors who cut the resource extraction and consumption in half?&lt;/p&gt;</description></item><item><title>The World in 30 Years</title><link>https://digikar99.github.io/microblog/p/climate-anxiety-dec-2025/</link><pubDate>Wed, 24 Dec 2025 21:05:40 +0530</pubDate><guid>https://digikar99.github.io/microblog/p/climate-anxiety-dec-2025/</guid><description>&lt;p&gt;What will happen to our world in 30 years? The past year I have been in acknowledgement of a recurring uneasiness. Earth&amp;rsquo;s climate is changing rapidly and accelerating. Different areas are warming up, cooling down, drying out, raining down, storming out faster than humans and non-human nature can keep up. It seems only inevitable that there will arise a certain sequence of years later this century that destroy all crops, flood all warehouses, kill all cattle, and bring people to famines.&lt;/p&gt;
&lt;p&gt;A part of me wants to accept the transient nature of life and all things and &amp;ldquo;do nothing at all&amp;rdquo;. A different part feels saddened, worried, hopeless, powerless at the state of 95% of the 8 billion humans and the trillion non-human animals. In large part, the situation is worsening, acceleratingly worsening, and a tiny fraction of humans are to blame. One can ask if life is possible without suffering and the answer seems no. Why does it even matter if we do anything or not?&lt;/p&gt;
&lt;p&gt;Is life possible without suffering?&lt;/p&gt;
&lt;p&gt;History has known at least one human, &lt;a class="link" href="https://en.wikipedia.org/wiki/The_Buddha" target="_blank" rel="noopener"
&gt;the Buddha&lt;/a&gt;, trying to grapple with the nature of suffering &amp;ndash; rather &lt;a class="link" href="https://en.wikipedia.org/wiki/Du%E1%B8%A5kha#Buddhism" target="_blank" rel="noopener"
&gt;dukkha&lt;/a&gt;. (But there are &lt;a class="link" href="https://en.wikipedia.org/wiki/Suffering#Philosophy" target="_blank" rel="noopener"
&gt;others&lt;/a&gt;.) Dukkha, in Buddhist Philosophy, means something slightly different from the meaning of the english term suffering. Dukkha means unsatisfactoriness, which captures what I have in mind. Unfortunately, Dukkha is one of the &lt;a class="link" href="https://en.wikipedia.org/wiki/Three_marks_of_existence" target="_blank" rel="noopener"
&gt;three marks of existence&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Buddhist way is &lt;a class="link" href="https://en.wikipedia.org/wiki/Buddhist_philosophy#The_Middle_Way" target="_blank" rel="noopener"
&gt;the Middle Way&lt;/a&gt; between the two extremes of ascetism and hedonism. It concerns &lt;a class="link" href="https://en.wikipedia.org/wiki/Noble_Eightfold_Path#The_eight_divisions" target="_blank" rel="noopener"
&gt;the Noble Eightfold Path&lt;/a&gt; that is expected to lead to the cessation of suffering. The eight folds or pillars include: right view (understanding), right resolve (thought), right speech, right action, right livelihood, right effort, right mindfulness, right samadhi (concentration). While useful as a general guideline for living, it seems to leave unanswered cases such as: self-defense and climate-change.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Self-defense&lt;/li&gt;
&lt;li&gt;Climate-change&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="link" href="https://www.reddit.com/r/Buddhism/comments/biakov/climate_tragedy_depression_and_buddhism_question/" target="_blank" rel="noopener"
&gt;Here&lt;/a&gt; is a long reddit post on climate-change and buddhism from 2019. The solution to climate anxiety might just be to accept the inevitable worsening and death whenever it happens, while trying to make positive contributions wherever possible.&lt;/p&gt;
&lt;p&gt;However, there is a third part of me, who identifies as a puzzle solver. The question it asks is this: Is life possible without suffering? More particularly, is there a way a civilization like that of humans can progress and perhaps reach the space age, without triggering a collapse of the ecosystem and food and water resources? Even if we acknowledge that most humans might fall prey to famines within the next 50-100 years, might there be a way for a new civilization to not repeat the mistakes of our civilization?&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;ve known me in real-life, you&amp;rsquo;d have heard me talking about &lt;a class="link" href="https://en.wikipedia.org/wiki/Doughnut_%28economic_model%29" target="_blank" rel="noopener"
&gt;Doughnut Economics&lt;/a&gt; this past year. It suggests that humans should use multidimensional metrics instead of GDP to measure well-being. And that human activity should be such that it does not exceed planetary boundaries. While the Doughnut Graphic is helpful to communicate to the general public, it remains deficient in rigor, that&amp;rsquo;d be necessary for modeling and concrete quantitative recommendations.&lt;/p&gt;
&lt;p&gt;It was difficult to imagine that Doughnut Economics was the only alternative economics model ever proposed over the past century and half. Indeed, a bit of searching (you can ask ChatGPT) will list you several. Are any of them useable for the new civilization?&lt;/p&gt;
&lt;p&gt;Perhaps, one of the fatal flaws in standard neoclassical economics &amp;ndash; both Capitalism and Marxism &amp;ndash; when it comes to interfacing with nature, is that it assumes raw materials are limited only by the means of production. This means, if you had enough means of production, you can get an unlimited supply of raw materials from nature. It does not consider that the number of trees might be finite. That clearing land for mining might have downstream effects. And so on and so forth. A second fatal flaw would be that it makes no claims about what happens or should happen to by-products, emissions, and wastes. These assumptions are fine when the human activity were no more than a fraction of what goes on in non-human world. Unfortunately, that is not the case. The scale of collective human activity is large enough to rival or even exceed that of non-human nature.&lt;/p&gt;
&lt;p&gt;Has anyone pondered how these different aspects can be integrated into economics?&lt;/p&gt;
&lt;p&gt;Enter &lt;a class="link" href="https://en.wikipedia.org/wiki/Nicholas_Georgescu-Roegen" target="_blank" rel="noopener"
&gt;Nicholas Georgescu-Roegen&lt;/a&gt;, a mathematician, statistician and an eventual economist. Through his &lt;a class="link" href="https://www.goodreads.com/book/show/624982.The_Entropy_Law_and_the_Economic_Process" target="_blank" rel="noopener"
&gt;The Entropy Law and the Economic Process&lt;/a&gt;, Georgescu-Roegen considers entropy from thermodynamics and suggests what it means for our (economic) system. For my purposes, the important point is that, entropy (disorder) of a closed system always increases. This is a fundamental law of the universe; no closed system is immune to this. This means a closed system should naturally evolve towards disorder.&lt;/p&gt;
&lt;p&gt;Yet, life &lt;em&gt;seems to&lt;/em&gt; disobey thermodynamics. It seems to evolve towards order. What explains this?&lt;/p&gt;
&lt;p&gt;Two points may be helpful. Firstly, that life is not a closed system. It exchanges matter as well as energy with its surroundings. Secondly, given a physical (chemical, nuclear, etc) process that emits energy, a part of that energy can be used to perform &lt;em&gt;useful&lt;/em&gt; work that can increase the order of a system. This is roughly known as &lt;a class="link" href="https://en.wikipedia.org/wiki/Gibbs_free_energy" target="_blank" rel="noopener"
&gt;Gibb&amp;rsquo;s Free Energy&lt;/a&gt;. Taken together, life can use free energy to create order and emit waste energy into its environment. Thus, the order can increase locally.&lt;/p&gt;
&lt;p&gt;Note, however, that the order-construction processes emit (waste) energy into its surroundings. Earth&amp;rsquo;s biosphere is remarkable at recycling its material resources &amp;ndash; carbon, oxygen, nitrogen and other elements. However, it is limited by physical laws in recycling energy. For Earth to remain habitable at a certain temperature, waste energy must leave the Earth. In the absence of large-scale human activity, one expects that there was &lt;a class="link" href="https://en.wikipedia.org/wiki/Earth%27s_energy_budget" target="_blank" rel="noopener"
&gt;a balance between the incoming and outgoing energy on Earth&lt;/a&gt;. Any energy received by the sun was either reflected or put to use by geological and biological systems to extract useful work. Eventually, the waste energy was released back into the atmosphere and eventually into space.&lt;/p&gt;
&lt;p&gt;The human activities underlying climate change have disturbed these energy exchanges. In particular, the larger amounts of greenhouse gases emitted by human activities have increased the amount of solar energy that remain in the atmosphere. I&amp;rsquo;d even suspect that harnessing fossil fuels, geothermal energy, as well solar energy from panels more efficient than plant leaves also increases the received energy. Call this latter as man-made energy. This is in contrast to other transformed energy such as hydroelectric or wind-energy. Man-made energy emits more energy, while the other forms of energies are mere conversions. Two possibilities arise:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Man-made energy is miniscule compared to the energy received from the sun. In this case, the civilization&amp;rsquo;s main concern would only be to keep the greenhouse gases at their pre-civilization levels. The Earth&amp;rsquo;s systems should take care of the rest. There arises the possibility that transformed energy reduces the amount of energy available to biological and geological systems. Thus, one can even disturb Earth&amp;rsquo;s systems without climate change. As of the current twenty-first century, &lt;a class="link" href="https://www.reddit.com/r/explainlikeimfive/comments/14v144s/eli5_do_wind_turbines_sap_a_lot_of_energy_from/" target="_blank" rel="noopener"
&gt;that windmills could affect Earth&amp;rsquo;s biosphere or geosphere seems unrealistic&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Man-made energy is significant compared to the energy received from the sun. To keep temperatures constant, this possibility will require devising ways to transmit the excess (waste heat) energy outside Earth.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In either case, a &amp;ldquo;natural&amp;rdquo; equilibrium will be attained as the Earth&amp;rsquo;s temperature rises. It will rise enough so that &lt;a class="link" href="https://en.wikipedia.org/wiki/Outgoing_longwave_radiation" target="_blank" rel="noopener"
&gt;the irradiated energy by the Earth&lt;/a&gt; equals the unreflected incoming energy and an equilibria is attained. Fortunately, this depends on the fourth power of absolute temperature, and, thus, only involves a small change in (average) temperatures. Unfortunately, the local effects of that small change in average temperature are rather large for the ecological, ocean, wind, rain, and human systems under consideration. This precisely is climate change.&lt;/p&gt;
&lt;p&gt;Zooming out, climate change is not going to melt Earth. It is rather a disequilibria in Earth&amp;rsquo;s energy budget. The Earth will adapt. Life will adapt. That in no way implies that life or civilization as we know it would continue the same. There will be changes. Significant and expensive ones at that.&lt;/p&gt;
&lt;p&gt;What about the new economic system? At least ChatGPT says this is an open problem. Following is a brief summary for anyone wanting to delve deeper:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Approach / School&lt;/th&gt;
&lt;th&gt;Key Figures&lt;/th&gt;
&lt;th&gt;Core Synthesis Idea&lt;/th&gt;
&lt;th&gt;How Order Is Created&lt;/th&gt;
&lt;th&gt;Main Economic Implication&lt;/th&gt;
&lt;th&gt;Degree of Formalization&lt;/th&gt;
&lt;th&gt;Main Limitation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dissipative-Structure Ecological Economics&lt;/td&gt;
&lt;td&gt;Prigogine, Ayres, Røpke&lt;/td&gt;
&lt;td&gt;Economies as far-from-equilibrium systems exporting entropy&lt;/td&gt;
&lt;td&gt;Energy throughput creates local order while increasing global entropy&lt;/td&gt;
&lt;td&gt;Sustainability depends on bounded entropy throughput&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Weak institutional detail&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Steady-State Bioeconomics&lt;/td&gt;
&lt;td&gt;Georgescu-Roegen, Daly&lt;/td&gt;
&lt;td&gt;Entropy law + biological regeneration constraints&lt;/td&gt;
&lt;td&gt;Qualitative development within fixed material/energy flows&lt;/td&gt;
&lt;td&gt;Zero growth in throughput, stable population &amp;amp; capital&lt;/td&gt;
&lt;td&gt;Low–Medium&lt;/td&gt;
&lt;td&gt;Limited dynamics, normatively heavy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Emergy Economics&lt;/td&gt;
&lt;td&gt;Howard &amp;amp; Elisabeth Odum&lt;/td&gt;
&lt;td&gt;Unified thermodynamics, biology, and valuation&lt;/td&gt;
&lt;td&gt;Energy hierarchy &amp;amp; transformity amplify usable order&lt;/td&gt;
&lt;td&gt;Prices and policy reflect embodied energy&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Contested valuation, hard market integration&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Thermo-Bioeconomic Growth Models&lt;/td&gt;
&lt;td&gt;van den Bergh, Kümmel&lt;/td&gt;
&lt;td&gt;Growth possible only if regeneration exceeds entropy&lt;/td&gt;
&lt;td&gt;Biological regeneration offsets entropy production&lt;/td&gt;
&lt;td&gt;Conditional, constrained growth&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Abstract, limited policy guidance&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Information-Theoretic / Evolutionary Economics&lt;/td&gt;
&lt;td&gt;Chaisson, Kauffman, Arthur&lt;/td&gt;
&lt;td&gt;Economic order as information accumulation&lt;/td&gt;
&lt;td&gt;Information reduces local entropy at energy cost&lt;/td&gt;
&lt;td&gt;Innovation bounded by energy dissipation&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Indirect link to policy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Technosphere / Autonomous Systems&lt;/td&gt;
&lt;td&gt;Peter Haff&lt;/td&gt;
&lt;td&gt;Civilization as self-directing energy system&lt;/td&gt;
&lt;td&gt;Order maintained by uncontrollable energy flows&lt;/td&gt;
&lt;td&gt;Human control over energy use is limited&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;td&gt;Pessimistic, weak prescriptions&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Earlier this year or the last, I also had a read at Peter Singer&amp;rsquo;s &lt;a class="link" href="https://en.wikipedia.org/wiki/How_Are_We_to_Live%3F" target="_blank" rel="noopener"
&gt;How are We to Live?&lt;/a&gt;. The claim was that an ethical life is fulfiling in itself. I do not remember if it preached a particular ethics framework; what it did preach is that one should live an ethical life simply because it is more fulfiling. Like with Buddhist philosophy, this works &amp;ldquo;by and large&amp;rdquo; as a general framework, without providing us a way to decide our actions from moment-to-moment. That requires a rigorous model of the world, the kind Nicholas Georgescu-Roegen might have aspired for.&lt;/p&gt;
&lt;p&gt;Unfortunately, then, there is no solution to &lt;em&gt;How are We to Live?&lt;/em&gt;, no answer to &lt;em&gt;Can life exist without suffering?&lt;/em&gt;, rigorous enough that one can structure one&amp;rsquo;s day to day life and local and national policies around them.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s sometimes not even clear whether anxiety is adaptive or malfunctioning. Perhaps, we would not even be in this mess if the richest and most-polluting people were more anxious (and foresightful?) in their actions.&lt;/p&gt;</description></item><item><title>Should I do a PhD?</title><link>https://digikar99.github.io/microblog/p/phd/</link><pubDate>Thu, 18 Dec 2025 09:08:16 +0530</pubDate><guid>https://digikar99.github.io/microblog/p/phd/</guid><description>&lt;p&gt;Am I qualified to answer this question? I don&amp;rsquo;t know. I&amp;rsquo;m just a second-year PhD student at the moment. You be the judge.&lt;/p&gt;
&lt;p&gt;What is a PhD? My understanding so far is it is a period of time (a few years) you spend under another academic (your supervisor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;learning how to be an academic in that particular field&lt;/li&gt;
&lt;li&gt;by doing research work&lt;/li&gt;
&lt;li&gt;that is in large parts independent as well as (ideally) collaborative&lt;/li&gt;
&lt;li&gt;that other academics too deem worth the time (a few years)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Does PhD requires research? Yes.&lt;/p&gt;
&lt;p&gt;Does research require PhD? No. Plenty of people throughout human history have made scientific and philosophical discoveries without doing a PhD. See &lt;a class="link" href="https://en.wikipedia.org/wiki/List_of_autodidacts#Scientists,_historians,_and_educators" target="_blank" rel="noopener"
&gt;List of Autodidacts&lt;/a&gt; and also Industry Research in your particular field.&lt;/p&gt;
&lt;p&gt;Does PhD put you on a guaranteed path to be an academic? No. Consider that, annually, an academic institute might churn out 5 PhD-holders, but might create a new assistant-professor position once every 5 years. That&amp;rsquo;s 25 PhD-qualified candidates for 1 position. Even if you consider that new academic institutes pop up, the number of new academic positions still remain several times below new PhD-qualified candidates. (Also see &lt;a class="link" href="https://www.nature.com/articles/d41586-025-01855-w" target="_blank" rel="noopener"
&gt;this Nature article&lt;/a&gt;.) In other words, unless you are damn good and damn lucky &lt;em&gt;even during your PhD&lt;/em&gt;, only then can you expect to get a good academic position. And let&amp;rsquo;s not forget that you have already been damn good and damn lucky just to &lt;em&gt;qualify for your PhD program&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;If other academics deem some research worth the time, that research must be good, right? No. What that merely implies is that that research is deemed worth the time (and money and resources) by other &lt;em&gt;academics&lt;/em&gt;. Surely, it must at least &lt;em&gt;correlate&lt;/em&gt; with good research?&lt;/p&gt;
&lt;p&gt;What is &lt;em&gt;good&lt;/em&gt; research? Surely, research on how to extract fossil fuels is good. For the &lt;em&gt;purposes of extracting fossil fueis&lt;/em&gt;. Research on how to exploit greater productivity from employees is good. For the &lt;em&gt;purpose of productivity-maximization&lt;/em&gt;. Research how to convert trees to better quality paper is good. For the &lt;em&gt;purpose of paper-manufacturing&lt;/em&gt;. But neither of these seem good for the &lt;em&gt;purpose of moving towards a sustainable equitable future&lt;/em&gt;. The point is &lt;em&gt;goodness&lt;/em&gt; of research is extra-scientific. There is no &lt;em&gt;scientific method&lt;/em&gt; to determine what qualifies as good research. To decide whether some research is good or not, you need to have a purpose in mind. Once you have some purpose, then research can be good or bad &lt;em&gt;towards that purpose&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;So far, that&amp;rsquo;s a pretty bleak picture of PhD. And it seems, one should not do a PhD at all! Not to mention PhD students are &lt;a class="link" href="https://sciencepolicy.ca/posts/the-high-price-of-low-funding-how-poor-graduate-student-support-is-hurting-canadas-scientific-community/" target="_blank" rel="noopener"
&gt;often&lt;/a&gt; &lt;a class="link" href="https://timesofindia.indiatimes.com/education/news/why-phd-scholars-feel-stipend-hike-is-below-the-mark/articleshow/104552086.cms" target="_blank" rel="noopener"
&gt;underpaid&lt;/a&gt;, stressed, and &lt;a class="link" href="https://insightintoacademia.com/doctoral-distress-graduate-program-pressures-impact-student-mental-health/" target="_blank" rel="noopener"
&gt;prone to depression and anxiety&lt;/a&gt; more than &lt;a class="link" href="https://www.nature.com/articles/d41586-024-03136-4" target="_blank" rel="noopener"
&gt;a matched sample not doing their PhD&lt;/a&gt;. Okay, that makes the motivation for PhD even bleaker.&lt;/p&gt;
&lt;p&gt;Why do a PhD at all then? Why do we do anything at all? Apparantly, because not doing that something incurs a greater perceived cost than doing it.&lt;/p&gt;
&lt;p&gt;A PhD gets you&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;several years worth of time to read and think on your own&lt;/li&gt;
&lt;li&gt;access to your supervisor, who you think is/was awesome&lt;/li&gt;
&lt;li&gt;opportunity to attend conferences with like minded people&lt;/li&gt;
&lt;li&gt;personal experience and behind the scenes happenings of academic publishing&lt;/li&gt;
&lt;li&gt;an affiliation that often times lets you be taken seriously or opens up access to journals&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further, a good academic or PhD environment also gets you&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;access to the history of your field&lt;/li&gt;
&lt;li&gt;access to not just your supervisor and conference attendees, but an entire department (= 24x7) with like minded people&lt;/li&gt;
&lt;li&gt;opportunity to be an academic relative of an awesome family of researchers&lt;/li&gt;
&lt;li&gt;a stipend that is less than awesome, but still enough to sustain a comfortable life&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And if you think doing good science requires knowing the&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;history [of the field]&lt;/li&gt;
&lt;li&gt;current happenings [of the field]&lt;/li&gt;
&lt;li&gt;ways of the minds and limitations of the awesome people [in the field],&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the PhD package - especially the one which is good - seem like a pretty good deal.&lt;/p&gt;
&lt;p&gt;Indeed, the earlier point that goodness of science needs to be evaluated extra-scientifically still stands. You must have a larger purpose in mind. The like-mindedness and awesome-ness is towards that larger purpose. Assuming you have that larger purpose in mind, you are the best judge whether a particular PhD program is &lt;em&gt;good for your purpose&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;And now you are also aware of the limitations of academic research described above.&lt;/p&gt;
&lt;p&gt;Beware, a bad or not-so-good PhD (or academic) environment often skips teaching you how to be an academic in a particular field. This is often implicit knowledge, and you ought to be a fair bit perceptive about how people and institutions work to figure it out. There are &lt;a class="link" href="https://www.goodreads.com/book/show/587478.A_PhD_Is_Not_Enough_" target="_blank" rel="noopener"
&gt;some&lt;/a&gt; &lt;a class="link" href="https://www.goodreads.com/book/show/35754925-write-smart-write-happy" target="_blank" rel="noopener"
&gt;books&lt;/a&gt; on this topic, but it is by and large knowledge that you will need to figure out in person through real-life interactions. Of course, you can consult your supervisor or other colleagues in the department or people you meet at the conferences. Such knowledge also gets described during late-night parties or social lunches at the labs or departments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Random note:&lt;/strong&gt; Scientific research is not a game (RPG) in which you unlock certain powers of the world by doing certain specific actions. There is no fixed set of actions that doing research involves. At best, it is like playing a very rich RPG &lt;em&gt;without a manual&lt;/em&gt;, and where quests are unlocked or solved on the span of years, decades and generations of humans. (Such a rich-enough RPG at a smaller scale would be fun! Though real-world is often more fun (= more complex).)&lt;/p&gt;</description></item><item><title>Classrooms, Questions, and Learning in India vs Europe</title><link>https://digikar99.github.io/microblog/p/selfstudy-handholding/</link><pubDate>Sat, 29 Nov 2025 20:44:15 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/selfstudy-handholding/</guid><description>&lt;p&gt;If you were schooled up in India (or other Asian countries too), you&amp;rsquo;d have unconsciously caught up the habit of staying silent in class. You might stay silent because you do not know or understand something, or for the fear of being labelled dumb, or for wanting to avoid feeling ashamed. Or you might remain silent because you understand it and do not want to attract attention. Some can be attention seekers. Some grow out of attention seeking. Some start to despise the special treatment and they too grow up to be silent*. And there could be other reasons. A fair few would also be fortunate enough to be exposed to discussion-oriented classes during schooling itself. India has a culture that shares deep respect for teachers or gurus. Unfortunately, the respect is also often replaced by fear.&lt;/p&gt;
&lt;p&gt;The median Indian student spends 10-12 years or more fearing teachers, or simply staying silent even without being fearful. Even if the student is now admitted to premier colleges in India, where many professors encourage discussions and class participation, it is hard to not remain silent. Conveniently progressing in such college requires participation. If you do not understand, you are expected to ask. The ones who ask, seek help and communicate, progress further than you. This continues through the rest of the undergraduate years. The ones fortunate enough to attend these premier undergraduate colleges, where professors encourage class participation and question asking, end up in a better position in terms of communication in graduate school life. But these students constitute single digit percentage of the student population.&lt;/p&gt;
&lt;p&gt;The median Indian student, however, spends another 3-4 years in an undergraduate program learning to stay silent. Even when the student is admitted to the graduate programs of premier colleges, they end up having to spend half their stay trying to unlearn the stay-silent habit, if that is meaningfully-possible at this stage of life at all.&lt;/p&gt;
&lt;p&gt;Over the past year, I have been fortunate to start my doctoral studies in Europe. One stark contrast compared to my graduate studies in India &amp;ndash; which itself was at a premier institute &amp;ndash; is the ease with which everyone asks questions. Many prefix their questions with &amp;ldquo;May be this is dumb (or silly)&amp;hellip;&amp;rdquo; but they ask. They ask while the topic is still being discussed. But they ask. Ask they do. It doesn&amp;rsquo;t matter if you are a first year graduate student. Or a senior professor attending an emeritus&amp;rsquo; professor&amp;rsquo;s lecture. Everyone asks questions. Indeed, people do modulate their questions in terms of whether they are clarifications, minor or serious objections, or tangential, but the question asking and discussion environment is prevalent.&lt;/p&gt;
&lt;p&gt;Another factor that discourages question asking in Indian schools includes &amp;ldquo;homework&amp;rdquo; &amp;ndash; The student is expected to ask questions only after putting in the &amp;ldquo;required&amp;rdquo; work. If one asks questions without putting in the &amp;ldquo;required&amp;rdquo; work, they may be shunned by the teacher. Even if not shunned upon, there is a serious culture that &amp;ldquo;mistakes are &lt;em&gt;bad&lt;/em&gt;&amp;rdquo;, &amp;ldquo;you should never do mistakes&amp;rdquo;, &amp;ldquo;asking questions is shameful&amp;rdquo;. This carried itself into the graduate school environment I experienced in India. It is indeed true that the amount of readings in graduate school keep increasing. In courses by some professors, they are outright impossible. Some expect an exposure, some expect a thorough reading, others expect somewhere in between. However, contrast the lack of question-asking with my experience here: students are shameless about asking questions, they are fearless about admitting they haven&amp;rsquo;t done their readings, they are truthful in acknowledging their weaknesses. The professors too reply in kind &amp;ndash; there&amp;rsquo;s no shunning of the student, there&amp;rsquo;s simply an answering that tries to clear the concept or point to the student without placing any judgment on the student.&lt;/p&gt;
&lt;p&gt;There are further implications of this &amp;ldquo;don&amp;rsquo;t ask questions&amp;rdquo; attitude especially when it comes to interdisciplinary collaboration. Interdisciplinary collaboration requires you to collaborate with someone whose background you can only acquire after years if not decades of hard work. This is impractical. The only other way is to admit your ignorance. Be open to learning. Be open to asking. Be open to asking dumb questions. Be open to feeling confused. Similarly, you too need to be open to the other person asking questions that seem nonsensical or dumb to you. Be empathetic towards them. Be understanding towards them. Be answering towards them without shunning.&lt;/p&gt;
&lt;p&gt;Acknowledge the situation, assume positive intentions, take a deep breath, and continue communication.&lt;/p&gt;
&lt;p&gt;I do not have an easy fix to the problem. Yet this contrast in discussion and question asking is something I have witnessed firsthand. If you happen notice yourself feeling ashamed, fearful, or any other negative emotion in classroom settings, despite having access to humble professors who are ready to answer any question, hopefully, this post will help you become more mindful of it, and be more open to asking questions, admitting your ignorance and learning more.&lt;/p&gt;
&lt;p&gt;I have indeed had the chance to witness great question askers and communicators, both in India and Europe. It isn&amp;rsquo;t beyond anyone. But it definitely requires an attitude shift in most of us. Happy asking! Happy Learning!&lt;/p&gt;
&lt;p&gt;*Of course, why a particular student or individual is more silent than others has multiple context-dependent reasons. On a different note, why a class might remain silent also has another set of reasons.&lt;/p&gt;</description></item><item><title>3-year Undergraduate Program in Computation and Behavioral Sciences</title><link>https://digikar99.github.io/microblog/p/teachyourselfcogsci/</link><pubDate>Sat, 29 Nov 2025 17:48:47 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/teachyourselfcogsci/</guid><description>&lt;p&gt;If you have ever discussed Cognitive Science with me for extended periods of time, then you&amp;rsquo;d know that I have often lamented about the need for a 10 year cognitive science &amp;ldquo;pre-graduate&amp;rdquo; program. However true it may be that acquiring relevant knowledge from all the different subdisciplines of Cognitive Science &amp;ndash; Psychology, Computer Science, Neuroscience, Philosophy, Linguistics, and Anthropology &amp;ndash; takes a long amount of time, such a program would be impractical for at least two main reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Impracticality of long-term planning:&lt;/strong&gt; To be employable by mid-20s at the latest requires starting by the age of 14 or 16. No sane person in this age group commits to a program so long, that too, with questionable financial or employment utility, especially in the 21st century.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inclination towards financially-wise choices:&lt;/strong&gt; It cannot be denied that everyone is trying to find a way or two to earn money by doing activities that aren&amp;rsquo;t so unpleasurable. In particular, people usually choose undergraduate (or even graduate) programs by the extent of their financial utility they generate. That&amp;rsquo;s not to say interests have no role. But given two things that look equally enticing in non-monetary terms, one is inclined to choose one that yields them better money.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Time and again, almost all the (senior) researchers I have come across in the field of Cognitive Science over the last 4 years have expressed that mathematical maturity goes a long way in any field of research including Cognitive Science. Interestingly, a related skill concerning programming is also an immensely useful skill in the 21st century in terms of its financial utility. Putting these two together, it seems that it might actually be possible to propose a standard 3- or 4-year undergraduate program that has both utilities (i) financial/employment (ii) research/higher-studies.&lt;/p&gt;
&lt;p&gt;As a doctoral student of Cognitive Science, I still lack any background in Linguistics, Neuroscience, or Anthropology. Whatever little I might have gained through occasional exposure is lost through time. So, I wouldn&amp;rsquo;t be able to suggest any specific resources for these disciplines. However, it seems by labeling the program as &amp;ldquo;Computation &lt;em&gt;and&lt;/em&gt; Behavioral Sciences&amp;rdquo;, I have already split the curriculum into two parts. Thus, anyone with a sufficient exposure from these other disciplines might be able to suggest the appropriate changes to the second part to come up with a corresponding &amp;ldquo;Computation and XYZ&amp;rdquo;. In fact, &lt;a class="link" href="https://catalog.mit.edu/degree-charts/computation-cognition-6-9/" target="_blank" rel="noopener"
&gt;MIT itself has a curriculum focusing on Neuroscience&lt;/a&gt;. My own preference for the curriculum comes from my exposure to &lt;a class="link" href="https://www.cgs.iitk.ac.in/MS_Program_CourseWork.php" target="_blank" rel="noopener"
&gt;Cognitive Science at IIT Kanpur&lt;/a&gt; and &lt;a class="link" href="https://cognitivescience.ceu.edu/curriculum-and-schedules" target="_blank" rel="noopener"
&gt;CEU&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Semester&lt;/th&gt;
&lt;th&gt;Computation&lt;/th&gt;
&lt;th&gt;Behavior&lt;/th&gt;
&lt;th&gt;Miscellaneous&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;Number Systems&lt;/td&gt;
&lt;td&gt;Introduction to Behavioral Science&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Mathematical Logic&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.1&lt;/td&gt;
&lt;td&gt;Coordinate Geometry&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.2&lt;/td&gt;
&lt;td&gt;Sets, Relations, Functions&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Probabilty Theory and Statistics&lt;/td&gt;
&lt;td&gt;Hypothesis Testing and Frequentist Methods&lt;/td&gt;
&lt;td&gt;Philosophy of Science&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Single-variable Calculus&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Introduction to Programming&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Multivariate Calculus&lt;/td&gt;
&lt;td&gt;Bayesian Statistics&lt;/td&gt;
&lt;td&gt;Philosophy of Mind&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Paradigms of Programming&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Linear Algebra&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Data Structures&lt;/td&gt;
&lt;td&gt;Basic Experimental Methods&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Discrete Structures I&lt;/td&gt;
&lt;td&gt;Classical Cognitive Science&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Practical Programming&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Databases&lt;/td&gt;
&lt;td&gt;Embodied, Extended, Enacted Cognition&lt;/td&gt;
&lt;td&gt;Formal Philosophy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Discrete Structures II&lt;/td&gt;
&lt;td&gt;&amp;lt;Elective I&amp;gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Machine Learning&lt;/td&gt;
&lt;td&gt;Computational Modeling&lt;/td&gt;
&lt;td&gt;Non-Classical Logic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&amp;lt;Elective II&amp;gt;&lt;/td&gt;
&lt;td&gt;&amp;lt;Elective III&amp;gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The nice thing about the above is even if one drops out by year 1 or year 2, they would already be familiar with numerous topics that are part of the computer science curriculum or its prerequisites. As &lt;a class="link" href="https://teachyourselfcs.com/" target="_blank" rel="noopener"
&gt;teachyourselfcs.com&lt;/a&gt; says: &lt;em&gt;There are 2 types of software engineer: those who understand computer science well enough to do challenging, innovative work, and those who just get by because they’re familiar with a few high level tools.&lt;/em&gt; The courses listed above are motivated for the later kinds of programmers.&lt;/p&gt;
&lt;p&gt;One objection to this curriculum can be that this is too heavily focused on Computer Science and Mathematics. The reasons are two-fold: Firstly, because many students opting for Behavioral Science due to a spite with Mathematics. Unfortunately, Mathematics comes back to bite people during their Graduate Studies, if not eventually in life. Secondly, an exposure to Data Structures, Discrete Structures, and Databases serves to provide more examples of &amp;ldquo;structures that the mind might use for computation&amp;rdquo;, thus helping the student and the eventual researcher keep an &amp;ldquo;open mind&amp;rdquo; once out of college.&lt;/p&gt;</description></item><item><title>Some issues with Probabilities and Bayesianism for Unified Models of Cognition or Artificial General Intelligence</title><link>https://digikar99.github.io/microblog/p/prob-issues/</link><pubDate>Fri, 14 Nov 2025 13:49:34 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/prob-issues/</guid><description>&lt;p&gt;Bayesian Methods provide a reasonable model of updating Probabilities of Beliefs in the face of upcoming information. Taken as a framework theory (unfalsifiable) of cognition or intelligence for a particular task, these can be pretty good for providing a precise null theory to compare cognition against (citation needed). Similarly, it also provides a good alternative to the Frequentist approaches to statistical inference.&lt;/p&gt;
&lt;p&gt;However, it becomes problematic when it starts being used as a model of unified cognition or general intelligence.&lt;/p&gt;
&lt;p&gt;Wikipedia provides the motivation for &lt;a class="link" href="https://en.wikipedia.org/wiki/Probability_theory" target="_blank" rel="noopener"
&gt;Probability Theory&lt;/a&gt; as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Probability is a way of assigning every &amp;ldquo;event&amp;rdquo; a value between zero and one, with the requirement that the event made up of all possible results (in our example, the event {1,2,3,4,5,6}) be assigned a value of one. To qualify as a probability distribution, the assignment of values must satisfy the requirement that if you look at a collection of mutually exclusive events (events that contain no common results, e.g., the events {1,6}, {3}, and {2,4} are all mutually exclusive), the probability that any of these events occurs is given by the sum of the probabilities of the events.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This already presents several issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You require a well-specified set. There&amp;rsquo;s no specification how to assign probability to a new event that is outside the set.&lt;/li&gt;
&lt;li&gt;Probabilities should be kept consistent with each other, respecting &lt;a class="link" href="https://en.wikipedia.org/wiki/Probability_axioms" target="_blank" rel="noopener"
&gt;its axioms&lt;/a&gt;. Not doing so leads to &lt;a class="link" href="https://en.wikipedia.org/wiki/Dutch_book_theorems#Dutch_books" target="_blank" rel="noopener"
&gt;Dutch books&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The uncertainties quantified by probabilities are relative uncertainties rather than absolute ones. This relates to the first point. &lt;a class="link" href="https://digikar99.github.io/microblog/p/nars-prob-nov-2025/" target="_blank" rel="noopener"
&gt;I have argued about this before.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;When one tries to quantify the uncertainty of all beliefs by probabilities, and tries to remain consistent, this can require updation across a wide range of beliefs. This can be computationally expensive. It is also dissimilar to humans who seem to be able to hold mutually contradictory beliefs (as long as they are &amp;ldquo;far apart&amp;rdquo; in reasoning chains).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To actually state the resulting unified model of cognition or general intelligence rigorously, one needs to specify what the probabilities are &lt;em&gt;of&lt;/em&gt;, that is, what are the elements of the set? I have seen zero discussion of this in Cognitive Science. Fortunately, there is a relevant entry in the &lt;a class="link" href="https://plato.stanford.edu/entries/logic-probability/" target="_blank" rel="noopener"
&gt;Stanford Encyclopaedia of Philosophy&lt;/a&gt; that discusses Modal Probability Logics and First-order Probability Logic.&lt;/p&gt;
&lt;p&gt;Classical mathematical (first-order) logic has several issues. Chapter 1 of Pei Wang&amp;rsquo;s book on &lt;a class="link" href="https://www.worldscientific.com/worldscibooks/10.1142/8665#t=aboutBook" target="_blank" rel="noopener"
&gt;Non-Axiomatic Logic&lt;/a&gt; discusses these. Several of them remain even after mixing probabilities and first order logics:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The truth-value itself may be dependent on assumptions. Thus, a change of assumptions (which a unified model of cognition must be able to handle) can necessitate revision of truth-values.&lt;/li&gt;
&lt;li&gt;Reasoning involves induction, abduction, analogy, and other types of inference beyond deduction itself.&lt;/li&gt;
&lt;li&gt;Classical logic leads to logically correct but intuitively problematic inferences. See &lt;a class="link" href="https://en.wikipedia.org/wiki/Paradoxes_of_material_implication" target="_blank" rel="noopener"
&gt;Paradoxes of Material Implication&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There is talk on how bayesian updates provides revision. There is work on how hierarchical bayesian models can be used for induction, abduction, etc. There is work on incorporating causality into probabilities. Intuitively, until they are fully specified, that is, as good as a mathematical theory, they are simply models of cognition with unspecified assumptions in the researchers&amp;rsquo; heads. They are not yet unified models of cognition that can be implemented in a machine to yield artificial general intelligence. Concretely, I still do not grasp the arguments.&lt;/p&gt;
&lt;p&gt;Is there an alternative? There are already &lt;a class="link" href="https://en.wikipedia.org/wiki/Outline_of_logic#Branches_of_logic" target="_blank" rel="noopener"
&gt;many branches of logic&lt;/a&gt;. There&amp;rsquo;s also a book written by Graham Priest on &lt;a class="link" href="https://en.wikipedia.org/wiki/An_Introduction_to_Non-Classical_Logic" target="_blank" rel="noopener"
&gt;Non-Classical Logic&lt;/a&gt;. And finally, the one that introduced me to these issues is Pei Wang&amp;rsquo;s work on &lt;a class="link" href="https://www.worldscientific.com/worldscibooks/10.1142/8665#t=aboutBook" target="_blank" rel="noopener"
&gt;Non-Axiomatic Logic&lt;/a&gt; that tries to draw upon several non-classical logics at once.&lt;/p&gt;</description></item><item><title>Software Development as simultaneous Prediction and Explanation</title><link>https://digikar99.github.io/microblog/p/software-explanation/</link><pubDate>Wed, 05 Nov 2025 19:34:01 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/software-explanation/</guid><description>&lt;p&gt;There is often the talk that prediction and explanation can be opposed to each other. Simple models aid explanability but may hinder prediction. Complex models aid prediction but may hinder explanability. Or so the story goes in my understanding.&lt;/p&gt;
&lt;p&gt;However, consider software development. Particularly of large softwares. Take &lt;a class="link" href="https://interestingengineering.com/lists/whats-the-biggest-software-package-by-lines-of-code" target="_blank" rel="noopener"
&gt;this&lt;/a&gt; for example.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google has 2 billion&lt;/li&gt;
&lt;li&gt;Mac OS has 80 million&lt;/li&gt;
&lt;li&gt;Microsoft Office has 40 million&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Perhaps, no Googler understands all of Google&amp;rsquo;s codebase, no Mac OS core-developer understands all of Mac OS, no developer of Microsoft Office understands all of Microsoft Office. Yet it is true that these are more-or-less reliable products produced by humans. It is true that individual humans fix bugs or add features to these behemoths.&lt;/p&gt;
&lt;p&gt;It is true that individual humans &lt;em&gt;do not understand&lt;/em&gt; these softwares in their entirety. However, an individual human &lt;em&gt;can understand&lt;/em&gt; different &lt;em&gt;aspects&lt;/em&gt; of the software once they put their mind to it. The task of combining the different &lt;em&gt;aspects&lt;/em&gt; into an interactable whole is left to the computer. Most well-maintained softwares have &lt;em&gt;potential understandability&lt;/em&gt; even if they are not &lt;em&gt;understandable&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In a similar manner, scientific explanations too can use the computer to construct &lt;em&gt;potentially understandable&lt;/em&gt; models without giving up on complexity. Taking inspiration from software development, one can build complex scientific models that may be &lt;em&gt;non-understandable&lt;/em&gt; but be &lt;em&gt;potentially understanable&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Of course, the task of coming up with a language to &lt;em&gt;program scientific explanation&lt;/em&gt; might be a lifetime of work in itself. Though, see &lt;a class="link" href="https://en.wikipedia.org/wiki/Structure_and_Interpretation_of_Classical_Mechanics" target="_blank" rel="noopener"
&gt;Structure and Interpretation of Classical Mechanics&lt;/a&gt;. (Might be unrelated &amp;ndash; I haven&amp;rsquo;t &lt;a class="link" href="https://groups.csail.mit.edu/mac/users/gjs/6946/sicm-html/" target="_blank" rel="noopener"
&gt;read&lt;/a&gt; it!)&lt;/p&gt;</description></item><item><title>A non-equivalence between Non-Axiomatic Logic and Probability Theory (Nov. 2025)</title><link>https://digikar99.github.io/microblog/p/nars-prob-nov-2025/</link><pubDate>Wed, 05 Nov 2025 18:32:41 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/nars-prob-nov-2025/</guid><description>&lt;p&gt;People have beliefs about the world*. The beliefs have uncertainties. How do we characterize or represent these uncertainties?&lt;/p&gt;
&lt;p&gt;In both the (computational) cognitive and computational sciences, beliefs are often represented as a parameter value $\theta = \theta_0$. The truth value of the belief may be true or false characterized by a scalar value $P(\theta = \theta_0)$, called the probability of the belief. The spread of the probability distribution $P(\theta)$ (often the standard deviation $\sigma$) gives us the uncertainty of the belief.&lt;/p&gt;
&lt;p&gt;However, note that this uncertainty is characterized in the context of a belief space, that is, the set $\mathit S$ of values of $\theta$. The uncertainty then is with respect to other beliefs $\theta_0' \neq \theta_0$.&lt;/p&gt;
&lt;p&gt;The &lt;a class="link" href="https://link.springer.com/book/10.1007/1-4020-5045-3" target="_blank" rel="noopener"
&gt;non-axiomatic logic framework&lt;/a&gt; by &lt;a class="link" href="https://cis.temple.edu/~pwang/" target="_blank" rel="noopener"
&gt;Pei Wang&lt;/a&gt; et al. instead characterize the truth-value of the belief by a two-length tuple $(f,c)$, the &lt;em&gt;frequency&lt;/em&gt; and the &lt;em&gt;confidence&lt;/em&gt; respectively. This allows us to characterize beliefs independently of each other. The different beliefs may later be compared against each other.&lt;/p&gt;
&lt;p&gt;Contrast the two situations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;10 coin tosses with 8 heads&lt;/li&gt;
&lt;li&gt;1000 coin tosses with 800 heads&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It is true that the bias of the coin in the second situation may be judged as being less uncertain than the first. Probability theory explains it as the two probability distributions same mean but different variations. Non-axiomatic logic explains it as two beliefs having the same frequency but different confidence.&lt;/p&gt;
&lt;p&gt;For the class of situations involving coin tosses, it is also the case that different values of $\theta$ are mutually exclusive. It is this mutual exclusivity that allows the use of Probability theory to model belief updates. In cases where mutual exclusivity fails, Probability theory becomes misapplied. NAL can take-over in those situations with contradictory beliefs.&lt;/p&gt;
&lt;p&gt;However, events can always be modeled so that they are mutually exclusive. To talk about the uncertainty of a particular belief $\theta = \theta_0$ independent of other beliefs $\theta = \theta_0'$ requires assigning each belief to its individual probability distribution. &lt;del&gt;Often this could be a normal distribution $\sout{\mathit N(\theta, \sigma)}$ characterized by a mean $\sout{\theta}$ and standard deviation $\sout{\sigma}$.&lt;/del&gt; However, this implies that the set of mutually exclusive alternatives is $\mathit S: \{\theta = \theta_0', \theta \neq \theta_0'\}$ and likewise for each value of $\theta$. Each of the two elements of the set can then obtain a probability independent of other values of $\theta$. But, this does not allow us to represent what might be considered the &lt;em&gt;uncertainty&lt;/em&gt; in probability.&lt;/p&gt;
&lt;p&gt;Even besides this non-equivalence, the two frameworks diverge a fair bit. Pei Wang has also talked about &lt;a class="link" href="https://arxiv.org/pdf/1303.1517" target="_blank" rel="noopener"
&gt;Belief Revision in Probability Theory&lt;/a&gt; discussing other issues with probabilities. I remain failed to grasp anything beyond intuitive ideas, perhaps, lacking a background in philosophy and history of probality theory or my own peculiarities. While Non-axiomatic Logic has seen a lot of development, it remains true that the research developments in Probability Theory has been humongous.&lt;/p&gt;
&lt;p&gt;*Or if you are a Cognitive Semanticist like Gardenfors, I&amp;rsquo;d restate as: these are beliefs about represented features of the world.&lt;/p&gt;</description></item><item><title>Memory (Oct. 2025)</title><link>https://digikar99.github.io/microblog/p/memory-oct-2025/</link><pubDate>Fri, 31 Oct 2025 13:00:08 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/memory-oct-2025/</guid><description>&lt;p&gt;How humans learn and store information and knowledge has been interesting to me. Although not enough to pursue a doctoral research on it. Although, it is also the case that I was advised not to silo myself into a &amp;ldquo;topic of cognition&amp;rdquo; but rather to start from an intriguing phenomenon and let that phenomenon guide my investigation. I think I like that advice.&lt;/p&gt;
&lt;p&gt;So, how do I think human learning and memory work? Here&amp;rsquo;s an attempt.&lt;/p&gt;
&lt;p&gt;Given an organism in an environment, the organism&amp;rsquo;s sensors make (transduce) sensory representations $S$ from the environment. This could involve electromagnetic radiation such as light, or vibrations such as by sound or ultrasound, or tactile such as by touch, or something more exotic. The environment may be external to the organism or it could be internal, to account for hunger, thirst, etc. For simplicity, one may assume that the same environment produces the same sensory representations. Thus, its sensors may be said to be &lt;em&gt;functional&lt;/em&gt; (as in &lt;a class="link" href="https://www.reddit.com/r/explainlikeimfive/comments/1cq60cn/eli5_what_is_functional_programming_and_how_is_it/" target="_blank" rel="noopener"
&gt;functional programming&lt;/a&gt;). If we allowed sensors to be non-functional in characteristic, it seems possible to attribute the entire process of cognition to sensors alone (citation needed). Such a sensory representation may also have a temporal component.&lt;/p&gt;
&lt;p&gt;Such a sensory representation $S$ only lasts very briefly (citations on classic sensory memory experiments). It must be &lt;em&gt;transformed&lt;/em&gt; into a conceptual representation $C_S$ for it to be available in the long run. The conceptual representation in turn may depend on an earlier conceptual structure, so we label the conceptual representation with a timestamp $t$: $C_{S,t}$. Doing so devoids the conceptual representation from a temporal component.&lt;/p&gt;
&lt;p&gt;It is ubiquitous that episodic (layman speak: contextual) and semantic (layman speak: context-free) memories are two aspects of our experience. How do these two aspects arise?&lt;/p&gt;
&lt;p&gt;A conceptual representation $C$ is a structure built out of concepts available from an existing concept-database $\mathcal C$. The structure may be atomic or compound. The concept databases includes atomic-concepts (nouns) as well as relation-concepts (adjectives, verbs, prepositions) to describe or combine existing structures into new compound structures. This raises several questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What are atomic-concepts? Or what determines whether some concept is atomic?&lt;/li&gt;
&lt;li&gt;How are relation-concepts created?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The concept database also allows us to compute the probability $P(C' | \mathcal C_{S,t}, S)$ of new conceptual structure $C'$ given the current concept-database $\mathcal C$, the current conceptual representation $C_{S,t}$, and sensory representation $S$. I use probability for convenience, but it could be any other measure of uncertainty.&lt;/p&gt;
&lt;p&gt;To answer the questions, we require postulating two concept-learning processes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first process $\mathcal P_{\text{atomic}}$ can make new atomic concepts out of sensory representations. An atomic concept $C'$ is characterized by &lt;em&gt;traces&lt;/em&gt; of sensory representations that were used to make the concept, as well as some conditional probabilities $P(C' | \mathcal C_{S,t}, S)$. What exact conditional probabilities are involved might be an open question. Perhaps they correspond to the concepts $C_{S,t}$ used to &lt;em&gt;predict&lt;/em&gt; this new concept $C&amp;rsquo;$? Additionally, what do I mean by &lt;em&gt;traces&lt;/em&gt;?&lt;/li&gt;
&lt;li&gt;The second process $\mathcal P_{\text{relational}}$ can make new relational concepts out of sensory representations as well as existing concepts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Stating this also partly answers question 2: A concept is atomic if it depends solely on sensory representations. A concept is relational if it depends on both sensory representations or other concepts. But this raises yet another question: what do I mean here by &lt;em&gt;depend on&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Semantic Memory is identical to the concept database $\mathcal C$.&lt;/p&gt;
&lt;p&gt;We say that a concept is &lt;em&gt;active&lt;/em&gt; if it is a part of the current conceptual representation $C_{S,t}$.&lt;/p&gt;
&lt;p&gt;Episodic Memory works as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The organisms cognitive system produces a sequence of conceptual representations $(C_1, &amp;hellip;, C_t)$ from the sucessive sensory representations its sensors produce. In a well-functioning organism, the production of such a sequence also creates a &lt;em&gt;sequence&lt;/em&gt; of &lt;em&gt;activations&lt;/em&gt; corresponding to different concepts. This sequence of activations is recorded by some cognitive-subsystem (perhaps hippocampus?).&lt;/li&gt;
&lt;li&gt;During recall, this sequence of activations is replayed back by the cognitive-subsystem that had recorded the activations. Because recall involves relations to concepts that are earlier or later in the sequence, episodic memory is conceptual.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Open questions include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What exactly do I mean by &lt;em&gt;depend&lt;/em&gt;?&lt;/li&gt;
&lt;li&gt;How exactly do the concept-generating processes operate? This needs to be specified in (much) more detail.&lt;/li&gt;
&lt;li&gt;What do I mean by &lt;em&gt;traces&lt;/em&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And finally, what predictions does this make?&lt;/p&gt;
&lt;p&gt;Of course, comparison with existing literature is an open task on its own.&lt;/p&gt;</description></item><item><title>Resume and CV Templates</title><link>https://digikar99.github.io/microblog/p/resume-cv/</link><pubDate>Fri, 31 Oct 2025 13:00:08 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/resume-cv/</guid><description>&lt;p&gt;A while ago, I had run up into an amazing reddit thread on resumes and CV template, suggestions and discussions. Here it is:&lt;/p&gt;
&lt;center&gt;
&lt;a class="link" href="https://www.reddit.com/r/jobs/comments/7y8k6p/im_an_exrecruiter_for_some_of_the_top_companies/"&gt;https://www.reddit.com/r/jobs/comments/7y8k6p/im_an_exrecruiter_for_some_of_the_top_companies/&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;It has pretty much kept being updated for the last&amp;hellip; 8 years(!)&lt;/p&gt;</description></item><item><title>Taking Consumerism out of Halloween to make it Sustainable</title><link>https://digikar99.github.io/microblog/p/halloween-2025/</link><pubDate>Fri, 31 Oct 2025 09:03:55 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/halloween-2025/</guid><description>&lt;p&gt;Today is yet another day humans will celebrate something with one-off products. Not bothering what happens to the products after they are used.&lt;/p&gt;
&lt;p&gt;They go the waste, right? Or may be you recycle them? And then, they &lt;em&gt;eventually&lt;/em&gt; go to the waste, right? Right.&lt;/p&gt;
&lt;p&gt;Did you you know that the &lt;a class="link" href="https://www.theguardian.com/environment/2020/dec/09/human-made-materials-now-outweigh-earths-entire-biomass-study" target="_blank" rel="noopener"
&gt;amount of plastic is greater than all land animals and marine animals combined&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;Well, plastic has become unavoidable. Yet, we can reduce single-purpose plastics as far as possible.&lt;/p&gt;
&lt;center&gt;
But how do I celebrate without dressing up?
&lt;/center&gt;
&lt;p&gt;This raises two questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How was Halloween celebrated historically?&lt;/li&gt;
&lt;li&gt;Can I still do a kinda-modern celebration without creating waste?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The first is an interesting question. A quick read at &lt;a class="link" href="https://en.wikipedia.org/wiki/Halloween" target="_blank" rel="noopener"
&gt;wikipedia&lt;/a&gt; tells us &lt;em&gt;&amp;ldquo;Wearing costumes and playing pranks at Halloween did not spread to England until the 20th century.&amp;rdquo;&lt;/em&gt; Roughly, consumerism is a very recent century or two old phenomena compared to the human history of several thousand years. &lt;a class="link" href="https://animalarchaeology.com/2018/10/31/terror-and-tradition-over-time-a-look-at-the-material-culture-of-halloween/" target="_blank" rel="noopener"
&gt;This&lt;/a&gt; might be a nice read.&lt;/p&gt;
&lt;p&gt;I still don&amp;rsquo;t know what exactly a &lt;em&gt;traditional Halloween celebration&lt;/em&gt; looks like? I&amp;rsquo;m told I should visit rural or semi-urban areas of Europe to find out.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s some nice &lt;a class="link" href="https://www.wastemanaged.co.uk/our-news/halloween/halloween-waste/" target="_blank" rel="noopener"
&gt;waste statistics on Modern Halloween&lt;/a&gt; by WasteManaged.&lt;/p&gt;
&lt;p&gt;As for the second question, there are plenty of guides once you start searching, for example, &lt;a class="link" href="https://www.forbes.com/sites/monicasanders/2025/10/27/5-ways-to-have-a-sustainable-spooky-season/" target="_blank" rel="noopener"
&gt;this article by Forbes&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;em&gt;Wish you all the best to a guilt-free celebration!&lt;/em&gt;
&lt;/center&gt;
&lt;p&gt;PS: If you created waste this year, that&amp;rsquo;s something to keep in mind for the upcoming celebrations! Be it Christmas, New Year, or the next Halloween! Or any other festivals you celebrate!&lt;/p&gt;</description></item><item><title>Documentation is Troublesome</title><link>https://digikar99.github.io/microblog/p/documentation/</link><pubDate>Thu, 30 Oct 2025 15:39:12 +0100</pubDate><guid>https://digikar99.github.io/microblog/p/documentation/</guid><description>&lt;p&gt;About two months ago, I decided to design a programming language with Python/Julia-like syntax that transpiled to Common Lisp. I called it &lt;a class="link" href="https://moonli-lang.github.io/" target="_blank" rel="noopener"
&gt;Moonli&lt;/a&gt;. It took about a month of reading, tinkering and thinking to play nice with the extensibility of Lisps. That was very challenging and rewarding. It&amp;rsquo;s usable now.&lt;/p&gt;
&lt;p&gt;But the hardest &amp;ndash; most boring &amp;ndash; part has been documentation. I intend the language to cater to people who are new to programming, or at least to Lisps. There have been excellent books on Lisps in general as well as Common Lisp in particular. However, many of them prevent free modification. There are some Common Lisp resources such as &lt;a class="link" href="https://lispcookbook.github.io/cl-cookbook/" target="_blank" rel="noopener"
&gt;The Cookbook&lt;/a&gt; that permit reuse, but unfortunately, to me, these do not feel suitable for a beginner. I had originally intended to rely on &lt;a class="link" href="https://allendowney.github.io/ThinkPython/" target="_blank" rel="noopener"
&gt;ThinkPython&lt;/a&gt;, but it quickly turned out that Lisp concepts can be fairly distant from Python*. Talk of the ideas of image-based development, REPL, symbols, seemed fairly distant (non-existent) in Python-land. Without these concepts, one is essentially throwing the Lisp baby out with the bath water.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m evaluating my options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hire someone: How much am I willing to pay? How familiar will they be with Lisp concepts?&lt;/li&gt;
&lt;li&gt;Post on lisp community: This feels like being lazy. On the other hand, it is true that after a certain point of time, writing code feels easier that explaining code. At least that&amp;rsquo;s true of me. An ideal documentor needs to be someone who actively enjoys &lt;em&gt;explaining&lt;/em&gt; code &amp;ndash; and writing down the explanations.&lt;/li&gt;
&lt;li&gt;Do it myself: I&amp;rsquo;m currently on this option, at least until I get a first draft. This will probably be slow. Yet, as long as I remain consistent at 6ish hours per week, I get 300 hours a year and 1500 hours over the course of 5 years. That&amp;rsquo;s a lot of time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Of course, if you wanted to start with Moonli, you can simply open up the Lisp REPL, load Moonli, and dig around and tinker until things start making sense to you. That&amp;rsquo;s how Lisp Hackers operate :).&lt;/p&gt;
&lt;p&gt;However, documentation has been a drag on life in general. Active thinking generates a &lt;em&gt;lot&lt;/em&gt; of thoughts. Connections from one topic to another, new ideas to try out the topics, multiple &lt;em&gt;aspects&lt;/em&gt; of the same topic linking to different topics in different ways. Often times, I end up leaving them as annotations in pdf files. The worries are two-fold:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If I haven&amp;rsquo;t documented my thoughts, what even was the use of thinking actively?&lt;/li&gt;
&lt;li&gt;If I document my thoughts, they at least need to be interpretable, and this slows down reading a lot.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;More so, it is fun to think at the edges. It is fun to make something that was difficult to conceptualize into something that is easier to conceptualize &lt;em&gt;for myself&lt;/em&gt;. However, the real &lt;em&gt;output&lt;/em&gt; of thinking lies in whether those conceptualizations make any sense &lt;em&gt;to others&lt;/em&gt;. But even after conceptualization, there is a step of explication that involves making those vague intuition-based concepts more precise, ideally precise enough for implementation as a computer program. Without this, I&amp;rsquo;m just cooking up stories or playing word-salad with no grounding. This is cumbersome.&lt;/p&gt;
&lt;p&gt;Summarized differently, knowledge may be divided into:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You know you know and have documented it for others to know.&lt;/li&gt;
&lt;li&gt;You know you know.&lt;/li&gt;
&lt;li&gt;You know you don&amp;rsquo;t know but you can figure it out.&lt;/li&gt;
&lt;li&gt;You know you don&amp;rsquo;t know how to figure it out, but can figure out how to figure it out.&lt;/li&gt;
&lt;li&gt;You know you don&amp;rsquo;t know nor how to figure out how to figure it out.&lt;/li&gt;
&lt;li&gt;You don&amp;rsquo;t know.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I can&amp;rsquo;t have any stances on what I don&amp;rsquo;t know, so 6 is out of discussion. 5 is what I enjoy, but 1 is where things pay off.&lt;/p&gt;
&lt;p&gt;*If anything, the use of Lisp concepts is one of the primary motivations to develop Moonli instead of using Python or Julia.&lt;/p&gt;</description></item><item><title>Advice for (Psychology) Graduate Students</title><link>https://digikar99.github.io/microblog/p/graduate-advice/</link><pubDate>Fri, 24 Oct 2025 08:45:32 +0200</pubDate><guid>https://digikar99.github.io/microblog/p/graduate-advice/</guid><description>&lt;p&gt;I recently received an email from one of my professors titled &lt;em&gt;Some non-obvious advice for psych graduate students&lt;/em&gt;. I wanted to share it publicly, but found no obvious public links in the email that was forwarded from one of Substack&amp;rsquo;s mailing list. Though, after inspecting the url for Varun Shennoy&amp;rsquo;s substack &lt;code&gt;varunshenoy.substack.com&lt;/code&gt; this morning, the critical part seemed to be obtaining some &lt;em&gt;username&lt;/em&gt;, and then the website should be at &lt;code&gt;&amp;lt;username&amp;gt;.substack.com&lt;/code&gt;. And there it was &lt;code&gt;paulbloom.substack.com&lt;/code&gt; that I could share publicly. Enough Meta!&lt;/p&gt;
&lt;p&gt;If you are a psychology graduate student (or perhaps even a postdoctoral researcher or someone in their early career), definitely check it out!&lt;/p&gt;
&lt;center&gt;
&lt;a class="link" href="https://smallpotatoes.paulbloom.net/p/some-non-obvious-advice-for-psych"&gt;
Some non-obvious advice for psych graduate students
&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;Another of Paul Bloom&amp;rsquo;s post I liked and can suggest reading is&lt;/p&gt;
&lt;center&gt;
&lt;a class="link" href="https://smallpotatoes.paulbloom.net/p/the-only-interdisciplinary-conversations"&gt;
The only interdisciplinary conversations worth having
&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;To be honest, that&amp;rsquo;s a strong take. I think from an interdisciplinary research perspective, it still makes sense. However, I also think there&amp;rsquo;s more to interdisciplinary research. I should share an article I had found another day; it&amp;rsquo;s a tangential topic on philosophy of interdisciplinary research rather than advice for graduate school.&lt;/p&gt;
&lt;p&gt;Coming back to graduate school advice, I had come across a book last year. I suspect it was this, but it could be different. It is slighly hefty at 400+ pages, but given that they are plain english rather than academic jargon, it should be an easy read over lunch hours or a weekend or two. Goodreads reviewers rate it quite highly.&lt;/p&gt;
&lt;center&gt;
&lt;a class="link" href="https://www.goodreads.com/book/show/52579211-a-field-guide-to-grad-school"&gt;
A Field Guide to Grad School: Uncovering the Hidden Curriculum
&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;Good luck!&lt;/p&gt;</description></item><item><title>Hallaoumi and Paneer</title><link>https://digikar99.github.io/microblog/p/halloumi/</link><pubDate>Fri, 24 Oct 2025 08:16:47 +0200</pubDate><guid>https://digikar99.github.io/microblog/p/halloumi/</guid><description>&lt;p&gt;Yesterday, I had a burger that reminded me of &lt;a class="link" href="https://en.wikipedia.org/wiki/Paneer" target="_blank" rel="noopener"
&gt;Indian Paneer&lt;/a&gt;. Indian Paneer is inturn different from &lt;a class="link" href="https://en.wikipedia.org/wiki/Beyaz_peynir" target="_blank" rel="noopener"
&gt;Turkish Peynir&lt;/a&gt; as I learnt from another friend. Upon checking the ingredients, this something in the Burger turned out to be &lt;a class="link" href="https://en.wikipedia.org/wiki/Halloumi" target="_blank" rel="noopener"
&gt;Halloumi&lt;/a&gt; with an origin in Cyprus.&lt;/p&gt;
&lt;p&gt;Though, I might be gravely mistaken to think Halloumi is in anyway similar to Paneer given &lt;a class="link" href="https://www.reddit.com/r/vegetarian/comments/t9gwbg/paneer_vs_halloumi/" target="_blank" rel="noopener"
&gt;this reddit post&lt;/a&gt; 😶‍🌫️&lt;/p&gt;</description></item><item><title>Extra extra protein and supplements!</title><link>https://digikar99.github.io/microblog/p/protein-supplement-safety/</link><pubDate>Thu, 23 Oct 2025 23:19:35 +0200</pubDate><guid>https://digikar99.github.io/microblog/p/protein-supplement-safety/</guid><description>&lt;p&gt;Some months ago, a friend recommended me the &lt;a class="link" href="https://www.youtube.com/@Viva-Longevity" target="_blank" rel="noopener"
&gt;Viva Longevity&lt;/a&gt; channel, and I occasionally watch it during brunch and dinner times.&lt;/p&gt;
&lt;p&gt;One particular video was about &lt;a class="link" href="https://www.youtube.com/watch?v=3LDe3k6lyac" target="_blank" rel="noopener"
&gt;protein obsession&lt;/a&gt;. I came across &lt;a class="link" href="https://www.cbc.ca/news/health/lead-protein-powders-shakes-9.6941833" target="_blank" rel="noopener"
&gt;another article by CBC Canada&lt;/a&gt; on a similar topic today.&lt;/p&gt;
&lt;p&gt;Essentially, if I recall correctly, at least in US (and Canada too), &lt;em&gt;extra protein&lt;/em&gt; products (and &lt;a class="link" href="https://www.youtube.com/watch?v=G8LG0OY3Izs" target="_blank" rel="noopener"
&gt;supplements too&lt;/a&gt;!) are not regulated as well as medicines. That means, they arrive in the market without the stringent safety standards that medicines are subject to. They may be taken off the market in retrospect &lt;em&gt;once they are proven unsafe&lt;/em&gt;. From the company&amp;rsquo;s perspective, this allows them to make profits against the health hazards they put up consumers against. This forms yet another example of crony-capitalism.&lt;/p&gt;
&lt;p&gt;Certainly, consume a healthy balanced diet focusing on unprocessed or minimally processed food. Think twice about supplements or other products sourced from industrial non-natural origins. When necessary, consult your doctors.&lt;/p&gt;</description></item><item><title>Don't major in Computer Science!</title><link>https://digikar99.github.io/microblog/p/no-computer-science/</link><pubDate>Thu, 23 Oct 2025 23:09:57 +0200</pubDate><guid>https://digikar99.github.io/microblog/p/no-computer-science/</guid><description>&lt;p&gt;From time to time, I regret majoring in computer science and not something heavier in mathematics. Today was one such day 🥲. It remains one of the biggest regrets of my life. Alas, what is done is done. Grass is always greener on the other side.&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://varunshenoy.substack.com/p/dont-major-in-computer-science" target="_blank" rel="noopener"
&gt;This post by Varun Shenoy&lt;/a&gt; sums it quite well. If you are young, and have an option, choose anything but computer science. And particularly, don&amp;rsquo;t go into computer science in order to learn programming. Programming is the bread and butter of 21st century, but this means it is a fundamental skill&amp;hellip; like english. You don&amp;rsquo;t become excited just because you know english. You need other skills, english is just a medium of communication (with other english-speakers). You need other skills, programming is just a means of communication (with the computer).&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t also go into computer science in order to pursue higher studies in computer science. The research part of computer science can be fairly heavy in mathematics, so I&amp;rsquo;m biased to say that an applied-math major would be better. Of course, you can start an undergraduation in computer science and fill it up with mathematics heavy topics, but why not acquire a proper mathematics background in the first place then.&lt;/p&gt;</description></item><item><title>Static Site Microblogging</title><link>https://digikar99.github.io/microblog/p/microblogging/</link><pubDate>Thu, 23 Oct 2025 22:45:15 +0200</pubDate><guid>https://digikar99.github.io/microblog/p/microblogging/</guid><description>&lt;p&gt;Over the last year or so, I have been sending whatsapp status updates fairly frequently. A friend recently asked me if something changed with me over the years 😆*. Well, I have no idea! But come to think of it, there was a time I used to post updates on facebook. Somehow, facebook has mostly subsided to the background over the years. There still exists a friend or two there, but most have moved to whatsapp.&lt;/p&gt;
&lt;p&gt;The issue with whatsapp status updates is they stay only for about 24 hours. Well, my status updates are less about the feels &amp;ndash; well, they are about the feels and music too &amp;ndash; but I also end up sharing (possibly?) informative youtube videos or news or anything interesting I find on the web. I myself sometimes find the need to refer back to something but only to have lost it. Essentially, status updates to me are a form of public diary that can often times be worth revisiting.&lt;/p&gt;
&lt;p&gt;Somehow I haven&amp;rsquo;t been able to integrate twitter or linkedin updates in my day to day life. LinkedIn is anyways not suitable for all updates. There is the Fediverse, but &lt;a class="link" href="https://www.reddit.com/r/RedditAlternatives/comments/1l51zqo/separating_forumscontentscommunityservers_from/" target="_blank" rel="noopener"
&gt;I think it needs a separation between community-servers and user-authentication-servers&lt;/a&gt;. Without it, it feels a inexorably fragmented and not worth the effort to me. Instagram is image centric, while my content is not. Threads is nice, but I&amp;rsquo;m learning it doesn&amp;rsquo;t play nice with users who only have Instagram installed. There there are other small and large platforms, but who knows if they will still be there in another decade. Wordpress is okay for long-form content, but it is still &lt;em&gt;very&lt;/em&gt; clunky.&lt;/p&gt;
&lt;p&gt;As a last resort, this is an attempt at static site based microblogging. I write my posts in a simple text editor, commit and push the changes to github, and they are converted to the site that you see. This is all powered by Hugo, in particular, the &lt;a class="link" href="https://stack.jimmycai.com/" target="_blank" rel="noopener"
&gt;Hugo Theme Stack&lt;/a&gt; designed by Jimmy Cai and supported by a 100+ contributors(!). In recent years, I&amp;rsquo;m definitely falling in love with hugo! If you have a website whose primary purpose is to perform one-way information dissemination from you to your audience, with no requirements for you to collect audience data, handle their logins and all, definitely check out Hugo and its wide collection of &lt;a class="link" href="https://themes.gohugo.io/themes/" target="_blank" rel="noopener"
&gt;themes&lt;/a&gt;. The installation and maintenance is remarkably smooth!&lt;/p&gt;
&lt;p&gt;The idea of using a text editor to make a simple post is fairly unappealing, so I&amp;rsquo;d be interested in seeing how this plays out for me. But the current theme has a ton of options. Particularly, tagging, since my content can be fairly disarrayed. So, you can simply click on the tags to see if there is something that interests you. And let&amp;rsquo;s see how this plays out.&lt;/p&gt;
&lt;p&gt;* &lt;em&gt;I just discovered, that &lt;a class="link" href="https://en.wikipedia.org/wiki/Emacs" target="_blank" rel="noopener"
&gt;emacs&lt;/a&gt; has an &lt;code&gt;M-x emoji-insert&lt;/code&gt; command that has a tooon of options 😱!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;** Well, this turned out to be long. But I promise, future posts will be short 🙃&lt;/p&gt;</description></item><item><title>Archives</title><link>https://digikar99.github.io/microblog/archives/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://digikar99.github.io/microblog/archives/</guid><description/></item><item><title>Search</title><link>https://digikar99.github.io/microblog/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://digikar99.github.io/microblog/search/</guid><description/></item><item><title>Tags</title><link>https://digikar99.github.io/microblog/tags/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://digikar99.github.io/microblog/tags/</guid><description/></item></channel></rss>